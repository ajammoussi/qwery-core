# ======================================================================
# RECEIVERS
# ======================================================================
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

# ======================================================================
# PROCESSORS
# ======================================================================
processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 512

  batch:
    timeout: 1s
    send_batch_size: 1024

  transform/promote_attributes:
    trace_statements:
      - context: span
        statements:
          # Total tokens = prompt + completion
          # Set both llm.total.tokens and agent.llm.total.tokens for compatibility
          # Using Int() function for OTTL (not ParseInt)
          - set(
              attributes["llm.total.tokens"],
              Int(attributes["agent.llm.prompt.tokens"])
              + Int(attributes["agent.llm.completion.tokens"])
            )
            where
              attributes["agent.llm.prompt.tokens"] != nil
              and attributes["agent.llm.completion.tokens"] != nil

          # Also set agent.llm.total.tokens for dashboard compatibility
          - set(
              attributes["agent.llm.total.tokens"],
              attributes["llm.total.tokens"]
            )
            where attributes["llm.total.tokens"] != nil

          # Promote actor type
          - set(attributes["agent.actor"], attributes["agent.actor.type"])
            where attributes["agent.actor.type"] != nil

          # Promote service name
          - set(attributes["application.type"], resource.attributes["service.name"])
            where resource.attributes["service.name"] != nil

          # Promote session/user id
          - set(attributes["user.id"], resource.attributes["session.id"])
            where resource.attributes["session.id"] != nil

# ======================================================================
# CONNECTORS
# ======================================================================
connectors:
  spanmetrics:
    histogram:
      unit: "ms"
      explicit:
        buckets: [100, 200, 500, 1000, 2000, 5000, 10000, 20000, 30000]
    dimensions:
      - name: agent.conversation.id
      - name: agent.actor
      - name: llm.total.tokens
      - name: agent.llm.total.tokens  # For dashboard compatibility
      - name: application.type
      - name: user.id

    # sum/tokens connector not available in this version, using transform processor instead

# ======================================================================
# EXPORTERS
# ======================================================================
exporters:
  clickhouse:
    endpoint: "http://clickhouse:8123"
    database: "default"
    username: "otel"
    password: "otel"

# ======================================================================
# SERVICE
# ======================================================================
service:
  telemetry:
    logs:
      level: error   # Minimal logging to reduce serial console output

  pipelines:
    traces:
      receivers: [otlp]
      processors:
        - memory_limiter
        - transform/promote_attributes
        - batch
      exporters:
        - spanmetrics  # Connector: receives traces, produces metrics
        - clickhouse

    metrics/spanmetrics:
      receivers: [spanmetrics]  # Connector: receives metrics from spanmetrics connector
      processors:
        - memory_limiter
        - batch
      exporters:
        - clickhouse

